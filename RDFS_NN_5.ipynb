{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 5 - following directly the algorithm in the paper, using existing class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from rdflib import Graph\n",
    "\n",
    "from utils import ResourceDictionary\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_nt_files(directory):\n",
    "    nt_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".nt\"):\n",
    "            nt_files.append(os.path.join(directory, file))\n",
    "    return nt_files\n",
    "\n",
    "\n",
    "def nt_files_to_dataframe(directory):\n",
    "    nt_files = get_nt_files(directory)\n",
    "    nt_files_df = pd.DataFrame(nt_files, columns=[\"nt_file\"])\n",
    "    return nt_files_df\n",
    "\n",
    "\n",
    "directory = \"data/lubm1_intact/graphs_with_descriptions\"\n",
    "nt_files_df = nt_files_to_dataframe(directory)\n",
    "nt_files_df = nt_files_df.sort_values(by=\"nt_file\").reset_index().drop(columns='index')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             nt_file\n0  data/lubm1_intact/graphs_with_descriptions/HTT...\n1  data/lubm1_intact/graphs_with_descriptions/HTT...\n2  data/lubm1_intact/graphs_with_descriptions/HTT...\n3  data/lubm1_intact/graphs_with_descriptions/HTT...\n4  data/lubm1_intact/graphs_with_descriptions/HTT...\n5  data/lubm1_intact/graphs_with_descriptions/HTT...\n6  data/lubm1_intact/graphs_with_descriptions/HTT...\n7  data/lubm1_intact/graphs_with_descriptions/HTT...\n8  data/lubm1_intact/graphs_with_descriptions/HTT...\n9  data/lubm1_intact/graphs_with_descriptions/HTT...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nt_file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_files_df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mart/anaconda3/envs/NMT4RDFS/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  del sys.path[0]\n",
      "/home/mart/anaconda3/envs/NMT4RDFS/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def read_csv_extract_columns(file_path, columns):\n",
    "    data = pd.read_csv(file_path)\n",
    "    extracted_data = data[columns]\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "csv_file_path = \"code/encoding.csv\"\n",
    "columns = [\"input_graph_file\", \"input_graph_encoding\", \"inference_file\", \"inference_graph_encoding\"]\n",
    "extracted_data = read_csv_extract_columns(csv_file_path, columns)\n",
    "extracted_data['input_graph_file'] = extracted_data['input_graph_file'].str.replace('^../', '')\n",
    "extracted_data['inference_file'] = extracted_data['inference_file'].str.replace('^../', '')\n",
    "extracted_data.input_graph_encoding = extracted_data.input_graph_encoding.apply(lambda x: ast.literal_eval(x))\n",
    "extracted_data.inference_graph_encoding = extracted_data.inference_graph_encoding.apply(lambda x: ast.literal_eval(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    input_graph_file  \\\n0  data/lubm1_intact/graphs_with_descriptions/HTT...   \n1  data/lubm1_intact/graphs_with_descriptions/HTT...   \n2  data/lubm1_intact/graphs_with_descriptions/HTT...   \n3  data/lubm1_intact/graphs_with_descriptions/HTT...   \n4  data/lubm1_intact/graphs_with_descriptions/HTT...   \n5  data/lubm1_intact/graphs_with_descriptions/HTT...   \n6  data/lubm1_intact/graphs_with_descriptions/HTT...   \n7  data/lubm1_intact/graphs_with_descriptions/HTT...   \n8  data/lubm1_intact/graphs_with_descriptions/HTT...   \n9  data/lubm1_intact/graphs_with_descriptions/HTT...   \n\n                                input_graph_encoding  \\\n0  {1: [(-1, 1)], 2: [(-1, -2)], 3: [(-3, -2), (-...   \n1  {1: [(-1, 3)], 7: [(-1, -2), (-3, -2), (-4, -2...   \n2  {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...   \n3      {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2)]}   \n4  {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...   \n5  {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...   \n6  {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...   \n7      {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2)]}   \n8  {1: [(-1, 3)], 7: [(-1, -2), (-3, -2), (-4, -2...   \n9  {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...   \n\n                                      inference_file  \\\n0  data/lubm1_intact/jena_inference_with_descript...   \n1  data/lubm1_intact/jena_inference_with_descript...   \n2  data/lubm1_intact/jena_inference_with_descript...   \n3  data/lubm1_intact/jena_inference_with_descript...   \n4  data/lubm1_intact/jena_inference_with_descript...   \n5  data/lubm1_intact/jena_inference_with_descript...   \n6  data/lubm1_intact/jena_inference_with_descript...   \n7  data/lubm1_intact/jena_inference_with_descript...   \n8  data/lubm1_intact/jena_inference_with_descript...   \n9  data/lubm1_intact/jena_inference_with_descript...   \n\n                            inference_graph_encoding  \n0  {1: [(-1, 2), (-682, 2), (-683, 2), (-684, 2),...  \n1  {1: [(-1, 4), (-1, 5), (-1, 6), (-1, 7), (-19,...  \n2                   {1: [(-2, 6), (-3, 6), (-4, 6)]}  \n3                                     {1: [(-2, 6)]}  \n4                            {1: [(-2, 6), (-3, 6)]}  \n5                   {1: [(-2, 6), (-3, 6), (-4, 6)]}  \n6                            {1: [(-2, 6), (-3, 6)]}  \n7                                     {1: [(-2, 6)]}  \n8  {1: [(-1, 4), (-1, 5), (-1, 6), (-1, 7), (-15,...  \n9                            {1: [(-2, 6), (-3, 6)]}  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_graph_file</th>\n      <th>input_graph_encoding</th>\n      <th>inference_file</th>\n      <th>inference_graph_encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 1)], 2: [(-1, -2)], 3: [(-3, -2), (-...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-1, 2), (-682, 2), (-683, 2), (-684, 2),...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 3)], 7: [(-1, -2), (-3, -2), (-4, -2...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-1, 4), (-1, 5), (-1, 6), (-1, 7), (-19,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-2, 6), (-3, 6), (-4, 6)]}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2)]}</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-2, 6)]}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-2, 6), (-3, 6)]}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-2, 6), (-3, 6), (-4, 6)]}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-2, 6), (-3, 6)]}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2)]}</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-2, 6)]}</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 3)], 7: [(-1, -2), (-3, -2), (-4, -2...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-1, 4), (-1, 5), (-1, 6), (-1, 7), (-15,...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>{1: [(-2, 6), (-3, 6)]}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'data/lubm1_intact/graphs_with_descriptions/HTTP_www.Department0.University0.edu.nt'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_files_df.nt_file[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=N24a7f2ee1ca94d88947828b4c1a465d4 (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ontology and RDF graphs\n",
    "ontology_file_tbox = \"data/updated/ub.nt\"\n",
    "ontology_file_abox = \"data/lubm1_intact/all_lubm.nt\"\n",
    "inference_graph_file = \"data/lubm1_intact/jena_inference_with_descriptions/HTTP_www.Department0.University0.edu.nt\"\n",
    "\n",
    "rdf_ontology = Graph()\n",
    "rdf_ontology.parse(ontology_file_tbox, format=\"nt\")\n",
    "rdf_ontology.parse(ontology_file_abox, format=\"nt\")\n",
    "rdf_inference_graph = Graph()\n",
    "rdf_inference_graph.parse(inference_graph_file, format=\"nt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_graphs_from_files(dataframe, file_column):\n",
    "    graphs = []\n",
    "    for file_path in dataframe[file_column]:\n",
    "        g = Graph()\n",
    "        full_path = os.path.abspath(file_path)\n",
    "        g.parse(full_path, format='nt')\n",
    "        graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "\n",
    "extracted_data['graph'] = create_graphs_from_files(extracted_data, 'input_graph_file')\n",
    "extracted_data['inference_graph'] = create_graphs_from_files(extracted_data, 'inference_file')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=Nebd474c91ccd470e84a01bf6c0e37bcf (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data.graph[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Step 1: Create properties dictionary\n",
    "property_query = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "SELECT DISTINCT ?property WHERE {\n",
    "  {\n",
    "    ?subject rdf:type ?object .\n",
    "    BIND(rdf:type as ?property)\n",
    "  } UNION {\n",
    "    ?property a owl:ObjectProperty .\n",
    "  } UNION {\n",
    "    ?property a owl:DatatypeProperty .\n",
    "  } UNION {\n",
    "    ?property a owl:TransitiveProperty .\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Define custom sorting function\n",
    "def custom_sort(property_uri):\n",
    "    property_str = str(property_uri)\n",
    "    if property_str == 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type':\n",
    "        return ('', property_str)\n",
    "    else:\n",
    "        return (property_str,)\n",
    "\n",
    "\n",
    "# Get the properties as a list and sort them\n",
    "property_list = [row.property for row in rdf_ontology.query(property_query)]\n",
    "sorted_properties = sorted(property_list, key=custom_sort)\n",
    "\n",
    "# Generate the properties dictionary\n",
    "#properties_dictionary = {property: index + 1 for index, property in enumerate(sorted_properties)}\n",
    "properties_dictionary = ResourceDictionary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(properties_dictionary)  ## SHOULD BE 32 +1 - paper page 26 line 36"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import rdflib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "additional_properties_2 = [\"http://www.w3.org/1999/02/22-rdf-syntax-ns#_1\",\n",
    "                           \"http://www.w3.org/1999/02/22-rdf-syntax-ns#first\",\n",
    "                           \"http://www.w3.org/1999/02/22-rdf-syntax-ns#object\",\n",
    "                           \"http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate\",\n",
    "                           \"http://www.w3.org/1999/02/22-rdf-syntax-ns#rest\",\n",
    "                           \"http://www.w3.org/1999/02/22-rdf-syntax-ns#subject\",\n",
    "                           \"http://www.w3.org/1999/02/22-rdf-syntax-ns#value\",\n",
    "                           \"http://www.w3.org/2000/01/rdf-schema#comment\",\n",
    "                           \"http://www.w3.org/2000/01/rdf-schema#domain\",\n",
    "                           \"http://www.w3.org/2000/01/rdf-schema#isDefinedBy\",\n",
    "                           \"http://www.w3.org/2000/01/rdf-schema#label\", \"http://www.w3.org/2000/01/rdf-schema#member\",\n",
    "                           \"http://www.w3.org/2000/01/rdf-schema#range\", \"http://www.w3.org/2000/01/rdf-schema#seeAlso\",\n",
    "                           \"http://www.w3.org/2000/01/rdf-schema#subClassOf\",\n",
    "                           \"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\",\n",
    "                           \"http://www.w3.org/2002/07/owl#imports\",\n",
    "                           \"http://www.w3.org/2002/07/owl#intersectionOf\", \"http://www.w3.org/2002/07/owl#inverseOf\",\n",
    "                           \"http://www.w3.org/2002/07/owl#onProperty\", \"http://www.w3.org/2002/07/owl#someValuesFrom\",\n",
    "                           \"http://www.w3.org/2002/07/owl#versionInfo\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "additional_properties = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "for property in additional_properties_2:\n",
    "    additional_properties.append(rdflib.URIRef(property))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "for property in sorted_properties:\n",
    "    if str(property) != \"http://swat.cse.lehigh.edu/onto/univ-bench.owl#officeNumber\":\n",
    "        properties_dictionary.add(property)\n",
    "\n",
    "for property in additional_properties:\n",
    "    properties_dictionary.add(property)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#advisor\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#affiliateOf\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#affiliatedOrganizationOf\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#age\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#degreeFrom\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#doctoralDegreeFrom\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#emailAddress\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#hasAlumnus\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#headOf\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#listedCourse\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#mastersDegreeFrom\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#member\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#memberOf\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#name\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#orgPublication\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationAuthor\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationDate\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationResearch\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#researchInterest\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#researchProject\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#softwareDocumentation\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#softwareVersion\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#subOrganizationOf\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#takesCourse\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#teacherOf\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#teachingAssistantOf\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#telephone\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#tenured\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#title\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#undergraduateDegreeFrom\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#worksFor\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_1\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#first\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#object\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#rest\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#subject\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#value\n",
      "http://www.w3.org/2000/01/rdf-schema#comment\n",
      "http://www.w3.org/2000/01/rdf-schema#domain\n",
      "http://www.w3.org/2000/01/rdf-schema#isDefinedBy\n",
      "http://www.w3.org/2000/01/rdf-schema#label\n",
      "http://www.w3.org/2000/01/rdf-schema#member\n",
      "http://www.w3.org/2000/01/rdf-schema#range\n",
      "http://www.w3.org/2000/01/rdf-schema#seeAlso\n",
      "http://www.w3.org/2000/01/rdf-schema#subClassOf\n",
      "http://www.w3.org/2000/01/rdf-schema#subPropertyOf\n",
      "http://www.w3.org/2002/07/owl#imports\n",
      "http://www.w3.org/2002/07/owl#intersectionOf\n",
      "http://www.w3.org/2002/07/owl#inverseOf\n",
      "http://www.w3.org/2002/07/owl#onProperty\n",
      "http://www.w3.org/2002/07/owl#someValuesFrom\n",
      "http://www.w3.org/2002/07/owl#versionInfo\n"
     ]
    }
   ],
   "source": [
    "for key in properties_dictionary.getKeys():\n",
    "    print(key)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# class_query = \"\"\"\n",
    "# PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "# PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "# PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "# SELECT DISTINCT ?class_name WHERE {\n",
    "#   {\n",
    "#     ?class_name a rdfs:Class .\n",
    "#   } UNION {\n",
    "#     ?class_name a owl:Class .\n",
    "#   }\n",
    "#   FILTER(isURI(?class_name))\n",
    "# }\n",
    "# \"\"\"\n",
    "#\n",
    "# unique_class_names = set(row.class_name for row in rdf_ontology.query(class_query))\n",
    "# sorted_class_names = sorted(unique_class_names, key=lambda x: str(x))\n",
    "#\n",
    "# global_resources_dictionary = {class_name: index + 1 for index, class_name in enumerate(sorted_class_names)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class_query = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "SELECT DISTINCT ?class_name WHERE {\n",
    "  {\n",
    "    ?class_name a rdfs:Class .\n",
    "  } UNION {\n",
    "    ?class_name a owl:Class .\n",
    "  }\n",
    "  FILTER(isURI(?class_name))\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "global_resources_dictionary = ResourceDictionary()\n",
    "for i, row in enumerate(rdf_ontology.query(class_query)):\n",
    "    global_resources_dictionary.add(row.class_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "43"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_resources_dictionary)  #SHOULD BE 57 - paper page 26 line 45"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<utils.ResourceDictionary at 0x7f4886d7dd50>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_resources_dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adding Missing Base Classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import rdflib\n",
    "\n",
    "base_classes = [\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#Alt\",\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#Bag\",\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#List\",\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#Property\",\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq\",\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#Statement\",\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#Class\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#Container\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#ContainerMembershipProperty\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#Datatype\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#Literal\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#Resource\",\n",
    "    \"http://www.w3.org/2001/XMLSchema#nonNegativeInteger\",\n",
    "    \"http://www.w3.org/2001/XMLSchema#string\"\n",
    "]\n",
    "\n",
    "for base_class in base_classes:\n",
    "    if rdflib.URIRef(base_class) not in global_resources_dictionary:\n",
    "        #global_resources_dictionary[rdflib.URIRef(base_class)] = len(global_resources_dictionary)\n",
    "        global_resources_dictionary.add(base_class)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "58"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_resources_dictionary)  #SHOULD BE 57 - paper page 26 line 45"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#AdministrativeStaff\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Article\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#AssistantProfessor\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#AssociateProfessor\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Book\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Chair\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Person\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Department\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#ClericalStaff\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#College\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#ConferencePaper\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Course\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Dean\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Director\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Program\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Employee\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Organization\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Faculty\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#FullProfessor\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#GraduateCourse\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#GraduateStudent\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Institute\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#JournalArticle\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Lecturer\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Manual\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#PostDoc\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Professor\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Publication\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Research\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#ResearchAssistant\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#ResearchGroup\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Schedule\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Software\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Specification\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Student\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#SystemsStaff\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#TeachingAssistant\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#TechnicalReport\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#UndergraduateStudent\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#University\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#UnofficialPublication\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#VisitingProfessor\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Work\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Alt\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Bag\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#List\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Property\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Statement\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral\n",
      "http://www.w3.org/2000/01/rdf-schema#Class\n",
      "http://www.w3.org/2000/01/rdf-schema#Container\n",
      "http://www.w3.org/2000/01/rdf-schema#ContainerMembershipProperty\n",
      "http://www.w3.org/2000/01/rdf-schema#Datatype\n",
      "http://www.w3.org/2000/01/rdf-schema#Literal\n",
      "http://www.w3.org/2000/01/rdf-schema#Resource\n",
      "http://www.w3.org/2001/XMLSchema#nonNegativeInteger\n",
      "http://www.w3.org/2001/XMLSchema#string\n"
     ]
    }
   ],
   "source": [
    "for key in global_resources_dictionary.getKeys():\n",
    "    print(key)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I don't know which one is wrong because all 58 of them are in zipped file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GLOBAL PROPERTIES AND RESOURCES DICTIONARIES DONE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# from rdflib.plugins.sparql import prepareQuery\n",
    "#\n",
    "# subproperty_query = prepareQuery(\"\"\"\n",
    "#     PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "#     SELECT ?property1 ?property2\n",
    "#     WHERE {\n",
    "#         ?property1 rdfs:subPropertyOf ?property2\n",
    "#         FILTER(?property1 != ?property2)\n",
    "#     }\n",
    "# \"\"\")\n",
    "#\n",
    "# subproperty_graph = nx.Graph()\n",
    "#\n",
    "# for row in rdf_ontology.query(subproperty_query):\n",
    "#     subproperty_graph.add_edge(row.property1, row.property2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "\n",
    "subproperty_query = prepareQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?property1 ?property2\n",
    "    WHERE {\n",
    "        ?property1 rdfs:subPropertyOf ?property2\n",
    "        FILTER(?property1 != ?property2)\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "subproperty_graph = nx.Graph()\n",
    "\n",
    "sub_properties_dict = {}\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for row in rdf_ontology.query(subproperty_query):\n",
    "    pairs.append((row.property1, row.property2))\n",
    "\n",
    "for (property1, property2) in pairs:\n",
    "    if property1 not in sub_properties_dict:\n",
    "        sub_properties_dict[property1] = []\n",
    "    sub_properties_dict[property1].append(property2)\n",
    "\n",
    "properties_connected_components = {}\n",
    "\n",
    "G = nx.Graph()\n",
    "for property1 in sub_properties_dict:\n",
    "    for property2 in sub_properties_dict[property1]:\n",
    "        G.add_edge(property1, property2)\n",
    "for property_uri in properties_dictionary:\n",
    "    G.add_node(property_uri)\n",
    "properties_connected_components = {}\n",
    "index = 0\n",
    "for c in nx.connected_components(G):\n",
    "    for p in c:\n",
    "        properties_connected_components[p] = index\n",
    "    index += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#mastersDegreeFrom 0\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#degreeFrom 0\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#doctoralDegreeFrom 0\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#undergraduateDegreeFrom 0\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#worksFor 1\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#memberOf 1\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#headOf 1\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type 2\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#advisor 3\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#affiliateOf 4\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#affiliatedOrganizationOf 5\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#age 6\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#emailAddress 7\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#hasAlumnus 8\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#listedCourse 9\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#member 10\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#name 11\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#orgPublication 12\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationAuthor 13\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationDate 14\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationResearch 15\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#researchInterest 16\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#researchProject 17\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#softwareDocumentation 18\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#softwareVersion 19\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#subOrganizationOf 20\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#takesCourse 21\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#teacherOf 22\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#teachingAssistantOf 23\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#telephone 24\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#tenured 25\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#title 26\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_1 27\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#first 28\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#object 29\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate 30\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#rest 31\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#subject 32\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#value 33\n",
      "http://www.w3.org/2000/01/rdf-schema#comment 34\n",
      "http://www.w3.org/2000/01/rdf-schema#domain 35\n",
      "http://www.w3.org/2000/01/rdf-schema#isDefinedBy 36\n",
      "http://www.w3.org/2000/01/rdf-schema#label 37\n",
      "http://www.w3.org/2000/01/rdf-schema#member 38\n",
      "http://www.w3.org/2000/01/rdf-schema#range 39\n",
      "http://www.w3.org/2000/01/rdf-schema#seeAlso 40\n",
      "http://www.w3.org/2000/01/rdf-schema#subClassOf 41\n",
      "http://www.w3.org/2000/01/rdf-schema#subPropertyOf 42\n",
      "http://www.w3.org/2002/07/owl#imports 43\n",
      "http://www.w3.org/2002/07/owl#intersectionOf 44\n",
      "http://www.w3.org/2002/07/owl#inverseOf 45\n",
      "http://www.w3.org/2002/07/owl#onProperty 46\n",
      "http://www.w3.org/2002/07/owl#someValuesFrom 47\n",
      "http://www.w3.org/2002/07/owl#versionInfo 48\n"
     ]
    }
   ],
   "source": [
    "for key, value in properties_connected_components.items():\n",
    "    print(key, value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# subgraphs = list(nx.connected_components(subproperty_graph))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# properties_groups = {}\n",
    "#\n",
    "# for group_id, subgraph in enumerate(subgraphs):\n",
    "#     for property in subgraph:\n",
    "#         properties_groups[property] = group_id\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# # Find the maximum group_id used so far\n",
    "# max_group_id = max(properties_groups.values()) if properties_groups else -1\n",
    "#\n",
    "# # Add the properties from properties_dictionary to the properties_groups\n",
    "# for property in properties_dictionary:\n",
    "#     if property not in properties_groups:\n",
    "#         max_group_id += 1\n",
    "#         properties_groups[property] = max_group_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "properties_groups = properties_connected_components"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TESTING DICTIONARIES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type 1\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#advisor 2\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#affiliateOf 3\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#affiliatedOrganizationOf 4\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#age 5\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#degreeFrom 6\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#doctoralDegreeFrom 7\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#emailAddress 8\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#hasAlumnus 9\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#headOf 10\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#listedCourse 11\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#mastersDegreeFrom 12\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#member 13\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#memberOf 14\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#name 15\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#orgPublication 16\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationAuthor 17\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationDate 18\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationResearch 19\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#researchInterest 20\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#researchProject 21\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#softwareDocumentation 22\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#softwareVersion 23\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#subOrganizationOf 24\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#takesCourse 25\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#teacherOf 26\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#teachingAssistantOf 27\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#telephone 28\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#tenured 29\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#title 30\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#undergraduateDegreeFrom 31\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#worksFor 32\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_1 33\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#first 34\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#object 35\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate 36\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#rest 37\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#subject 38\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#value 39\n",
      "http://www.w3.org/2000/01/rdf-schema#comment 40\n",
      "http://www.w3.org/2000/01/rdf-schema#domain 41\n",
      "http://www.w3.org/2000/01/rdf-schema#isDefinedBy 42\n",
      "http://www.w3.org/2000/01/rdf-schema#label 43\n",
      "http://www.w3.org/2000/01/rdf-schema#member 44\n",
      "http://www.w3.org/2000/01/rdf-schema#range 45\n",
      "http://www.w3.org/2000/01/rdf-schema#seeAlso 46\n",
      "http://www.w3.org/2000/01/rdf-schema#subClassOf 47\n",
      "http://www.w3.org/2000/01/rdf-schema#subPropertyOf 48\n",
      "http://www.w3.org/2002/07/owl#imports 49\n",
      "http://www.w3.org/2002/07/owl#intersectionOf 50\n",
      "http://www.w3.org/2002/07/owl#inverseOf 51\n",
      "http://www.w3.org/2002/07/owl#onProperty 52\n",
      "http://www.w3.org/2002/07/owl#someValuesFrom 53\n",
      "http://www.w3.org/2002/07/owl#versionInfo 54\n"
     ]
    }
   ],
   "source": [
    "for key in properties_dictionary:\n",
    "    print(key, properties_dictionary[key])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#AdministrativeStaff 1\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Article 2\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#AssistantProfessor 3\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#AssociateProfessor 4\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Book 5\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Chair 6\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Person 7\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Department 8\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#ClericalStaff 9\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#College 10\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#ConferencePaper 11\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Course 12\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Dean 13\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Director 14\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Program 15\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Employee 16\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Organization 17\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Faculty 18\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#FullProfessor 19\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#GraduateCourse 20\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#GraduateStudent 21\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Institute 22\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#JournalArticle 23\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Lecturer 24\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Manual 25\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#PostDoc 26\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Professor 27\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Publication 28\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Research 29\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#ResearchAssistant 30\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#ResearchGroup 31\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Schedule 32\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Software 33\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Specification 34\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Student 35\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#SystemsStaff 36\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#TeachingAssistant 37\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#TechnicalReport 38\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#UndergraduateStudent 39\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#University 40\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#UnofficialPublication 41\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#VisitingProfessor 42\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#Work 43\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Alt 44\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Bag 45\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#List 46\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Property 47\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq 48\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#Statement 49\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral 50\n",
      "http://www.w3.org/2000/01/rdf-schema#Class 51\n",
      "http://www.w3.org/2000/01/rdf-schema#Container 52\n",
      "http://www.w3.org/2000/01/rdf-schema#ContainerMembershipProperty 53\n",
      "http://www.w3.org/2000/01/rdf-schema#Datatype 54\n",
      "http://www.w3.org/2000/01/rdf-schema#Literal 55\n",
      "http://www.w3.org/2000/01/rdf-schema#Resource 56\n",
      "http://www.w3.org/2001/XMLSchema#nonNegativeInteger 57\n",
      "http://www.w3.org/2001/XMLSchema#string 58\n"
     ]
    }
   ],
   "source": [
    "for key in global_resources_dictionary:\n",
    "    print(key, global_resources_dictionary[key])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#mastersDegreeFrom 0\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#degreeFrom 0\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#doctoralDegreeFrom 0\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#undergraduateDegreeFrom 0\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#worksFor 1\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#memberOf 1\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#headOf 1\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type 2\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#advisor 3\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#affiliateOf 4\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#affiliatedOrganizationOf 5\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#age 6\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#emailAddress 7\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#hasAlumnus 8\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#listedCourse 9\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#member 10\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#name 11\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#orgPublication 12\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationAuthor 13\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationDate 14\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#publicationResearch 15\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#researchInterest 16\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#researchProject 17\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#softwareDocumentation 18\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#softwareVersion 19\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#subOrganizationOf 20\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#takesCourse 21\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#teacherOf 22\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#teachingAssistantOf 23\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#telephone 24\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#tenured 25\n",
      "http://swat.cse.lehigh.edu/onto/univ-bench.owl#title 26\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_1 27\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#first 28\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#object 29\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate 30\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#rest 31\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#subject 32\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#value 33\n",
      "http://www.w3.org/2000/01/rdf-schema#comment 34\n",
      "http://www.w3.org/2000/01/rdf-schema#domain 35\n",
      "http://www.w3.org/2000/01/rdf-schema#isDefinedBy 36\n",
      "http://www.w3.org/2000/01/rdf-schema#label 37\n",
      "http://www.w3.org/2000/01/rdf-schema#member 38\n",
      "http://www.w3.org/2000/01/rdf-schema#range 39\n",
      "http://www.w3.org/2000/01/rdf-schema#seeAlso 40\n",
      "http://www.w3.org/2000/01/rdf-schema#subClassOf 41\n",
      "http://www.w3.org/2000/01/rdf-schema#subPropertyOf 42\n",
      "http://www.w3.org/2002/07/owl#imports 43\n",
      "http://www.w3.org/2002/07/owl#intersectionOf 44\n",
      "http://www.w3.org/2002/07/owl#inverseOf 45\n",
      "http://www.w3.org/2002/07/owl#onProperty 46\n",
      "http://www.w3.org/2002/07/owl#someValuesFrom 47\n",
      "http://www.w3.org/2002/07/owl#versionInfo 48\n"
     ]
    }
   ],
   "source": [
    "for key in properties_groups:\n",
    "    print(key, properties_groups[key])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PROPERTIES GROUPS DONE - CREATE CATALOGUE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_lubm_graph_type(s):\n",
    "    s = s.split('/')[-1]\n",
    "    s = s.split('_')[-1]\n",
    "    m = re.search(\"\\d\", s)\n",
    "    return s[:m.start()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df_catalogue = pd.DataFrame()\n",
    "df_catalogue[\"input_graph_file\"] = extracted_data.input_graph_file\n",
    "df_catalogue[\"inference_file\"] = extracted_data.inference_file\n",
    "\n",
    "df_catalogue[\"graph_type\"] = df_catalogue.input_graph_file.apply(get_lubm_graph_type)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    input_graph_file  \\\n0  data/lubm1_intact/graphs_with_descriptions/HTT...   \n1  data/lubm1_intact/graphs_with_descriptions/HTT...   \n2  data/lubm1_intact/graphs_with_descriptions/HTT...   \n3  data/lubm1_intact/graphs_with_descriptions/HTT...   \n4  data/lubm1_intact/graphs_with_descriptions/HTT...   \n\n                                      inference_file          graph_type  \n0  data/lubm1_intact/jena_inference_with_descript...      www.Department  \n1  data/lubm1_intact/jena_inference_with_descript...  AssistantProfessor  \n2  data/lubm1_intact/jena_inference_with_descript...         Publication  \n3  data/lubm1_intact/jena_inference_with_descript...         Publication  \n4  data/lubm1_intact/jena_inference_with_descript...         Publication  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_graph_file</th>\n      <th>inference_file</th>\n      <th>graph_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>www.Department</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>AssistantProfessor</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>Publication</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>Publication</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>Publication</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catalogue.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CATALOGUE DONE - START ENCODING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# GLOBAL PROPERTIES DICTIONARY - properties_dictionary - already exists\n",
    "global_properties_dictionary = properties_dictionary  #ResourceDictionary\n",
    "\n",
    "global_active_properties_dictionary = {}\n",
    "# GLOBAL RESOURCES DICTIONARY - global_resources_dictionary - already exists #RESOURCEDICTIONARY\n",
    "\n",
    "global_active_resources_dictionary = {}\n",
    "# GLOBAL PROPERTY GROUPS DICTIONARY  - properties_groups\n",
    "global_property_groups_dictionary = properties_groups  # already exists\n",
    "# LOCAL RESOURCES DICTIONARY [graph name] -> (local props, local resources)\n",
    "# local_resources_dictionaries = {}\n",
    "global_local_resources_dictionary = {}\n",
    "global_property_IDs = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from graph_words_encoder import GraphWordsEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "graph_words_encoder = GraphWordsEncoder(global_properties_dictionary, global_property_groups_dictionary,\n",
    "                                        global_resources_dictionary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ENCODING DONE - START TESTING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 17174 graphs\n"
     ]
    }
   ],
   "source": [
    "encodings = []\n",
    "encodings_inference = []\n",
    "\n",
    "graphs_test = []\n",
    "inference_test = []\n",
    "number_of_tests = len(extracted_data.graph)\n",
    "\n",
    "\n",
    "def compare_dictionaries(dict1, dict2):\n",
    "    mismatched_pairs = []\n",
    "    for key in set(dict1.keys()).union(dict2.keys()):\n",
    "        if key in dict1 and key in dict2:\n",
    "            if dict1[key] != dict2[key]:\n",
    "                mismatched_pairs.append((key, dict1[key], dict2[key]))\n",
    "        else:\n",
    "            missing_in = \"dict1\" if key not in dict1 else \"dict2\"\n",
    "            print(f\"Key {key} is missing in {missing_in}\")\n",
    "    return mismatched_pairs\n",
    "\n",
    "\n",
    "for i in range(number_of_tests):\n",
    "    graphs_test.append(extracted_data.graph[i])\n",
    "    inference_test.append(extracted_data.inference_graph[i])\n",
    "\n",
    "print(f\"Encoding {number_of_tests} graphs\")\n",
    "\n",
    "for i in range(number_of_tests):\n",
    "    encoding, resources_dictionary = graph_words_encoder.encode_graph(graphs_test[i], inference=False)\n",
    "    encoding_inference, _ = graph_words_encoder.encode_graph(inference_test[i], resources_dictionary, inference=True)\n",
    "    encodings.append(encoding)\n",
    "    encodings_inference.append(encoding_inference)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error count: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z in range(number_of_tests):\n",
    "    error_count = 0\n",
    "    # print(f\"# Testing encoding for graph, layer:{z} = `{extracted_data.input_graph_file[z].split('/')[-1]}`\\n\")\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            # print(\"## Testing encoding for input graph\\n\")\n",
    "            encoding1 = encodings[z]\n",
    "            encoding2 = extracted_data.input_graph_encoding[z]\n",
    "        else:\n",
    "            # print(\"## Testing encoding for inference graph\\n\")\n",
    "            encoding1 = encodings_inference[z]\n",
    "            encoding2 = extracted_data.inference_graph_encoding[z]\n",
    "\n",
    "        mismatched_pairs = compare_dictionaries(encoding1, encoding2)\n",
    "\n",
    "        # print(f\"### Mismatched key-value pairs for layer {z}:\\n\")\n",
    "\n",
    "        if len(mismatched_pairs) != 0:\n",
    "            error_count += 1\n",
    "            # print(\"  No mismatched pairs found\\n\")\n",
    "        else:\n",
    "            for key, value1, value2 in mismatched_pairs:\n",
    "                print(f\"#### Key {key}:\\n\")\n",
    "                print(\"  Incorrect value:\\n`\", value1, \"`\\n\")\n",
    "                print(\"  Correct value:\\n`\", value2, \"`\\n\")\n",
    "                print()\n",
    "\n",
    "print(f\"Error count: {error_count}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "df_catalogue[\"input_graph_encoding\"] = extracted_data.input_graph_encoding\n",
    "df_catalogue[\"inference_graph_encoding\"] = extracted_data.inference_graph_encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    input_graph_file  \\\n0  data/lubm1_intact/graphs_with_descriptions/HTT...   \n1  data/lubm1_intact/graphs_with_descriptions/HTT...   \n2  data/lubm1_intact/graphs_with_descriptions/HTT...   \n3  data/lubm1_intact/graphs_with_descriptions/HTT...   \n4  data/lubm1_intact/graphs_with_descriptions/HTT...   \n\n                                      inference_file          graph_type  \\\n0  data/lubm1_intact/jena_inference_with_descript...      www.Department   \n1  data/lubm1_intact/jena_inference_with_descript...  AssistantProfessor   \n2  data/lubm1_intact/jena_inference_with_descript...         Publication   \n3  data/lubm1_intact/jena_inference_with_descript...         Publication   \n4  data/lubm1_intact/jena_inference_with_descript...         Publication   \n\n                                input_graph_encoding  \\\n0  {1: [(-1, 1)], 2: [(-1, -2)], 3: [(-3, -2), (-...   \n1  {1: [(-1, 3)], 7: [(-1, -2), (-3, -2), (-4, -2...   \n2  {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...   \n3      {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2)]}   \n4  {1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...   \n\n                            inference_graph_encoding  \n0  {1: [(-1, 2), (-682, 2), (-683, 2), (-684, 2),...  \n1  {1: [(-1, 4), (-1, 5), (-1, 6), (-1, 7), (-19,...  \n2                   {1: [(-2, 6), (-3, 6), (-4, 6)]}  \n3                                     {1: [(-2, 6)]}  \n4                            {1: [(-2, 6), (-3, 6)]}  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_graph_file</th>\n      <th>inference_file</th>\n      <th>graph_type</th>\n      <th>input_graph_encoding</th>\n      <th>inference_graph_encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>www.Department</td>\n      <td>{1: [(-1, 1)], 2: [(-1, -2)], 3: [(-3, -2), (-...</td>\n      <td>{1: [(-1, 2), (-682, 2), (-683, 2), (-684, 2),...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>AssistantProfessor</td>\n      <td>{1: [(-1, 3)], 7: [(-1, -2), (-3, -2), (-4, -2...</td>\n      <td>{1: [(-1, 4), (-1, 5), (-1, 6), (-1, 7), (-19,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>Publication</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...</td>\n      <td>{1: [(-2, 6), (-3, 6), (-4, 6)]}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>Publication</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2)]}</td>\n      <td>{1: [(-2, 6)]}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>data/lubm1_intact/graphs_with_descriptions/HTT...</td>\n      <td>data/lubm1_intact/jena_inference_with_descript...</td>\n      <td>Publication</td>\n      <td>{1: [(-1, 8)], 4: [(-1, -2)], 11: [(-1, -2), (...</td>\n      <td>{1: [(-2, 6), (-3, 6)]}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catalogue.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create graph words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "active_properties_size = len(graph_words_encoder.active_properties)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "graph_words_array = np.zeros((len(encodings), active_properties_size), dtype=np.int16)\n",
    "inference_graph_words_array = np.zeros((len(encodings_inference), active_properties_size), dtype=np.int16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "graph_words_catalogue = ResourceDictionary()\n",
    "for graph_index, graph_encoding in enumerate(encodings):\n",
    "    for k in sorted(graph_encoding):\n",
    "        p = graph_encoding[k]\n",
    "        sorted_p = sorted(p, key=lambda element: (element[0], element[1]))\n",
    "        tpl = tuple(sorted_p)\n",
    "        graph_words_catalogue.add(tpl)\n",
    "        graph_words_array[graph_index, k - 1] = graph_words_catalogue[tpl]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "inference_graph_words_catalogue = ResourceDictionary()\n",
    "for graph_index, graph_encoding in enumerate(encodings_inference):\n",
    "    for k in sorted(graph_encoding):\n",
    "        p = graph_encoding[k]\n",
    "        sorted_p = sorted(p, key=lambda element: (element[0], element[1]))\n",
    "        tpl = tuple(sorted_p)\n",
    "        inference_graph_words_catalogue.add(tpl)\n",
    "        inference_graph_words_array[graph_index, k - 1] = inference_graph_words_catalogue[tpl]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "df_catalogue[\"input_graph_words\"] = graph_words_array.tolist()\n",
    "df_catalogue[\"inference_graph_words\"] = inference_graph_words_array.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create matrix embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "MAXIMUM_MATRIX_SIZE = 800\n",
    "HOPE_EMBEDDING_SIZE = 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "matrix_embedding_catalogue = np.zeros(\n",
    "    (len(graph_words_catalogue) + 1, MAXIMUM_MATRIX_SIZE * HOPE_EMBEDDING_SIZE))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "def embed_layer_hope(layer, embedding_dim):\n",
    "    beta = 0.01\n",
    "    svd = TruncatedSVD(n_components=embedding_dim, random_state=42)\n",
    "    M_g = np.eye(layer.shape[0]) - beta * layer\n",
    "    M_l = beta * layer\n",
    "    S = np.dot(np.linalg.inv(M_g), M_l)\n",
    "    u = svd.fit_transform(S)\n",
    "    vt = svd.components_\n",
    "    s = svd.singular_values_\n",
    "    X1 = np.dot(u, np.diag(np.sqrt(s)))\n",
    "    X2 = np.dot(vt.T, np.diag(np.sqrt(s)))\n",
    "\n",
    "    return X1, X2\n",
    "\n",
    "\n",
    "def reconstruct_layer(u, v, alpha=0.5):\n",
    "    r = np.dot(u, v.T)\n",
    "    r[r >= alpha] = 1\n",
    "    r[r < alpha] = 0\n",
    "    return r"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:34<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for graph_word in tqdm(graph_words_catalogue):\n",
    "    layer_adjacency_matrix = graph_words_encoder.layer_to_np(graph_word,\n",
    "                                                             len(graph_words_encoder.active_classes),\n",
    "                                                             MAXIMUM_MATRIX_SIZE)\n",
    "\n",
    "    x1, x2 = embed_layer_hope(layer_adjacency_matrix, int(HOPE_EMBEDDING_SIZE / 2))\n",
    "    reconstructed_layer = reconstruct_layer(x1 * 100, x2 * 100, 0.1)\n",
    "    matrix_embedding_catalogue[graph_words_catalogue[graph_word]] = np.concatenate(\n",
    "        (x1.flatten() * 100, x2.flatten() * 100), axis=0)\n",
    "    if not np.allclose(layer_adjacency_matrix, reconstructed_layer):\n",
    "        print(\"Reconstruction layer failed, increase hope embedding size. Current embedding size = %\",\n",
    "              HOPE_EMBEDDING_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LUBM1 graph words dataset of size 17174\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded LUBM1 graph words dataset of size {len(df_catalogue)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=0.6, validate_percent=0.2, stratify=None, seed=1):\n",
    "    val_test_percent = 1 - train_percent\n",
    "    test_percent = (1 - (train_percent + validate_percent))\n",
    "    test_percent = test_percent / (test_percent + validate_percent)\n",
    "    if stratify:\n",
    "        df_train, df_val_test = train_test_split(df, test_size=val_test_percent, random_state=seed,\n",
    "                                                 stratify=df[stratify])\n",
    "        df_val, df_test = train_test_split(df_val_test, test_size=test_percent, random_state=seed,\n",
    "                                           stratify=df_val_test[stratify])\n",
    "    else:\n",
    "        df_train, df_val_test = train_test_split(df, test_size=val_test_percent, random_state=seed)\n",
    "        df_val, df_test = train_test_split(df_val_test, test_size=test_percent, random_state=seed)\n",
    "    return df_train, df_val, df_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "TRAINING_SET_PERCENT = 0.6\n",
    "VALIDATION_SET_PERCENT = 0.2\n",
    "\n",
    "rdf_data_train, rdf_data_val, rdf_data_test = train_validate_test_split(df_catalogue,\n",
    "                                                                        train_percent=TRAINING_SET_PERCENT,\n",
    "                                                                        validate_percent=VALIDATION_SET_PERCENT,\n",
    "                                                                        stratify=\"graph_type\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train, validation and test sets with 60.0%, 20.0% and 20.0% respectively\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Splitting dataset into train, validation and test sets with {TRAINING_SET_PERCENT * 100}%, {VALIDATION_SET_PERCENT * 100}% and {100 - TRAINING_SET_PERCENT * 100 - VALIDATION_SET_PERCENT * 100}% respectively\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "    # Returns\n",
    "        A binary matrix representation of the input.\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype=np.int)\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=np.bool)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def get_target_vocab_size(df_train):\n",
    "    y = df_train['inference_graph_words']\n",
    "    y = np.stack(y)\n",
    "    return y.max() + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def create_input_target_arrays(rdf_dataframe, embed_matrix, vocab_size):\n",
    "    x_input = rdf_dataframe['input_graph_words']\n",
    "    x_input = np.stack(x_input)\n",
    "    x_input = embed_matrix[x_input]\n",
    "    y_target = rdf_dataframe['inference_graph_words']\n",
    "    y_target = np.stack(y_target)\n",
    "    y_target_categorical = to_categorical(y_target, vocab_size)\n",
    "    return x_input, y_target_categorical"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 21:08:26.768077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-06 21:08:27.328175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-06 21:08:27.328192: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-06 21:08:28.586032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-06 21:08:28.586112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-06 21:08:28.586120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout, Bidirectional, GRU, RepeatVector, TimeDistributed\n",
    "from keras.models import Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "from nn_utils import CSVLoggerTimed, to_categorical, true_acc\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def create_graph_words_translation_model(x, y):\n",
    "    graph_input = Input(shape=(x.shape[1], x.shape[2]), name='input_graph_words_sequence')\n",
    "    graph_input_dense = Dense(256, name='graph_input_dense')(graph_input)\n",
    "    graph_dropout1 = Dropout(0.2, name='graph_dropout1')(graph_input_dense)\n",
    "    graph_gru = Bidirectional(GRU(128, name=\"gru_sequence_encoder\"), name='bidirectional')(graph_dropout1)\n",
    "    graph_dropout2 = Dropout(0.2, name='graph_dropout2')(graph_gru)\n",
    "    hidden_graph = RepeatVector(y.shape[1], name=\"repeat_vector\")(graph_dropout2)\n",
    "    inference_output = GRU(128, return_sequences=True, name='sequence_decoder')(hidden_graph)\n",
    "    inference_output = Dropout(0.2, name=\"output_dropout\")(inference_output)\n",
    "    inference_output = TimeDistributed(Dense(y.shape[2], name=\"softmax_layer\", activation='softmax'),\n",
    "                                       name=\"inference_graph_words_sequence\")(inference_output)\n",
    "    inference_model = Model(graph_input, inference_output)\n",
    "    inference_model.compile('adam', 'categorical_crossentropy', metrics=['accuracy', true_acc])\n",
    "    return inference_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# matrix_embedding_catalogue\n",
    "vocab_size = get_target_vocab_size(rdf_data_train)\n",
    "x_train, y_train = create_input_target_arrays(rdf_data_train, matrix_embedding_catalogue, vocab_size)\n",
    "x_val, y_val = create_input_target_arrays(rdf_data_val, matrix_embedding_catalogue, vocab_size)\n",
    "x_test, y_test = create_input_target_arrays(rdf_data_test, matrix_embedding_catalogue, vocab_size)\n",
    "\n",
    "inference_model = create_graph_words_translation_model(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_graph_words_sequence   [(None, 18, 3200)]       0         \n",
      " (InputLayer)                                                    \n",
      "                                                                 \n",
      " graph_input_dense (Dense)   (None, 18, 256)           819456    \n",
      "                                                                 \n",
      " graph_dropout1 (Dropout)    (None, 18, 256)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              296448    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " graph_dropout2 (Dropout)    (None, 256)               0         \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 18, 256)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequence_decoder (GRU)      (None, 18, 128)           148224    \n",
      "                                                                 \n",
      " output_dropout (Dropout)    (None, 18, 128)           0         \n",
      "                                                                 \n",
      " inference_graph_words_seque  (None, 18, 490)          63210     \n",
      " nce (TimeDistributed)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,327,338\n",
      "Trainable params: 1,327,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.info(\"Created NN model: \")\n",
    "inference_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "EPOCHS = 10  # 200\n",
    "BATCH_SIZE = 32"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "LOGGING_FOLDER = \"logs\"\n",
    "MODEL_FOLDER = \"models\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "csv_logger = CSVLoggerTimed(LOGGING_FOLDER + '/training.csv', separator=',', append=True)\n",
    "tensorboard = TensorBoard(log_dir=LOGGING_FOLDER)\n",
    "modelcheckpoint = ModelCheckpoint(MODEL_FOLDER + '/best_model', monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                  save_weights_only=True, mode='auto', period=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_25118/3257632537.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Starting training for %s epochs \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m inference_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE,\n\u001B[1;32m      3\u001B[0m                     callbacks=[csv_logger, tensorboard, modelcheckpoint])\n\u001B[1;32m      4\u001B[0m \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Finished training\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting training for %s epochs \", EPOCHS)\n",
    "inference_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    callbacks=[csv_logger, tensorboard, modelcheckpoint])\n",
    "logging.info(\"Finished training\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info(\"Evaluating on test set\")\n",
    "test_eval = inference_model.evaluate(x_test, y_test)\n",
    "logging.info(\"Test set accuracy: %s\", test_eval[inference_model.metrics_names.index('true_acc')])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
