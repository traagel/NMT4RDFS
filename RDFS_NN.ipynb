{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# RDFS NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Dropout, Bidirectional, GRU, RepeatVector, TimeDistributed\n",
    "from keras.models import Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "col_names=[\"subject\", \"predicate\", \"object\"]\n",
    "df = pd.read_csv(\"./data/jupyter/all_lubm.nt\", delimiter=' ', names=col_names)\n",
    "df['object'] = df['object'].apply(lambda x: x.rstrip('.'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  subject  \\\ncount                                              100573   \nunique                                              17189   \ntop     <http://www.Department0.University0.edu/FullPr...   \nfreq                                                   14   \n\n                                                predicate        object  \ncount                                              100573        100573  \nunique                                                 18         13948  \ntop     <http://swat.cse.lehigh.edu/onto/univ-bench.ow...  xxx-xxx-xxxx  \nfreq                                                21489          8330  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>predicate</th>\n      <th>object</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100573</td>\n      <td>100573</td>\n      <td>100573</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>17189</td>\n      <td>18</td>\n      <td>13948</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>&lt;http://www.Department0.University0.edu/FullPr...</td>\n      <td>&lt;http://swat.cse.lehigh.edu/onto/univ-bench.ow...</td>\n      <td>xxx-xxx-xxxx</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>14</td>\n      <td>21489</td>\n      <td>8330</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "subjects = df[\"subject\"].unique()\n",
    "predicates = df[\"predicate\"].unique()\n",
    "objects = df[\"object\"].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_encoded = df.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "subject_to_id = {subject: i for i, subject in enumerate(subjects)}\n",
    "predicate_to_id = {predicate: i for i, predicate in enumerate(predicates)}\n",
    "object_to_id = {object: i for i, object in enumerate(objects)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_encoded[\"subject\"] = df[\"subject\"].map(subject_to_id)\n",
    "df_encoded[\"predicate\"] = df[\"predicate\"].map(predicate_to_id)\n",
    "df_encoded[\"object\"] = df[\"object\"].map(object_to_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "        subject  predicate  object\n0             0          0       0\n1             0          1       1\n2             0          1       2\n3             0          2       3\n4             0          3       4\n5             0          4       5\n6             0          5       6\n7             1          3       7\n8             1          6       8\n9             1          5       9\n10            2          0      10\n11            2          1      11\n12            2          2       3\n13            2          7      12\n14            2          3      13\n15            2          8      14\n16            2          4      15\n17            2          5      16\n18            2          5      17\n19            3          0      18\n20            3          1      19\n21            3          1      20\n22            3          2       3\n23            3          3      21\n24            3          8      22\n25            3          4      23\n26            3          5       6\n27            4          0      10\n28            4          1      24\n29            4          1      25\n...         ...        ...     ...\n100543    17180          5       9\n100544    17181          3    1074\n100545    17181          5     253\n100546    17182          0      10\n100547    17182          1    4851\n100548    17182          1     242\n100549    17182          1     637\n100550    17182          1    2221\n100551    17182          2       3\n100552    17182          3     736\n100553    17182          8    2930\n100554    17182          4   13947\n100555    17182          5       6\n100556    17183          3      76\n100557    17183          6    4205\n100558    17183          5       9\n100559    17184          3    4824\n100560    17184          5     253\n100561    17185          3      98\n100562    17185          6    1314\n100563    17185          5       9\n100564    17186          3     513\n100565    17186          6     715\n100566    17186          5       9\n100567    17187          3      51\n100568    17187          6    5910\n100569    17187          5       9\n100570    17188          3     577\n100571    17188          6    2562\n100572    17188          5       9\n\n[100573 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>predicate</th>\n      <th>object</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2</td>\n      <td>1</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2</td>\n      <td>7</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2</td>\n      <td>8</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>4</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>5</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>5</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>3</td>\n      <td>0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>3</td>\n      <td>1</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>3</td>\n      <td>1</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3</td>\n      <td>3</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>3</td>\n      <td>8</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>3</td>\n      <td>4</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>3</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>4</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>4</td>\n      <td>1</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100543</th>\n      <td>17180</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>100544</th>\n      <td>17181</td>\n      <td>3</td>\n      <td>1074</td>\n    </tr>\n    <tr>\n      <th>100545</th>\n      <td>17181</td>\n      <td>5</td>\n      <td>253</td>\n    </tr>\n    <tr>\n      <th>100546</th>\n      <td>17182</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>100547</th>\n      <td>17182</td>\n      <td>1</td>\n      <td>4851</td>\n    </tr>\n    <tr>\n      <th>100548</th>\n      <td>17182</td>\n      <td>1</td>\n      <td>242</td>\n    </tr>\n    <tr>\n      <th>100549</th>\n      <td>17182</td>\n      <td>1</td>\n      <td>637</td>\n    </tr>\n    <tr>\n      <th>100550</th>\n      <td>17182</td>\n      <td>1</td>\n      <td>2221</td>\n    </tr>\n    <tr>\n      <th>100551</th>\n      <td>17182</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>100552</th>\n      <td>17182</td>\n      <td>3</td>\n      <td>736</td>\n    </tr>\n    <tr>\n      <th>100553</th>\n      <td>17182</td>\n      <td>8</td>\n      <td>2930</td>\n    </tr>\n    <tr>\n      <th>100554</th>\n      <td>17182</td>\n      <td>4</td>\n      <td>13947</td>\n    </tr>\n    <tr>\n      <th>100555</th>\n      <td>17182</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>100556</th>\n      <td>17183</td>\n      <td>3</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>100557</th>\n      <td>17183</td>\n      <td>6</td>\n      <td>4205</td>\n    </tr>\n    <tr>\n      <th>100558</th>\n      <td>17183</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>100559</th>\n      <td>17184</td>\n      <td>3</td>\n      <td>4824</td>\n    </tr>\n    <tr>\n      <th>100560</th>\n      <td>17184</td>\n      <td>5</td>\n      <td>253</td>\n    </tr>\n    <tr>\n      <th>100561</th>\n      <td>17185</td>\n      <td>3</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>100562</th>\n      <td>17185</td>\n      <td>6</td>\n      <td>1314</td>\n    </tr>\n    <tr>\n      <th>100563</th>\n      <td>17185</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>100564</th>\n      <td>17186</td>\n      <td>3</td>\n      <td>513</td>\n    </tr>\n    <tr>\n      <th>100565</th>\n      <td>17186</td>\n      <td>6</td>\n      <td>715</td>\n    </tr>\n    <tr>\n      <th>100566</th>\n      <td>17186</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>100567</th>\n      <td>17187</td>\n      <td>3</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>100568</th>\n      <td>17187</td>\n      <td>6</td>\n      <td>5910</td>\n    </tr>\n    <tr>\n      <th>100569</th>\n      <td>17187</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>100570</th>\n      <td>17188</td>\n      <td>3</td>\n      <td>577</td>\n    </tr>\n    <tr>\n      <th>100571</th>\n      <td>17188</td>\n      <td>6</td>\n      <td>2562</td>\n    </tr>\n    <tr>\n      <th>100572</th>\n      <td>17188</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n<p>100573 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_dataframe_translation_model_LSTM(df):\n",
    "    input_texts = df['subject'].str.cat(df['predicate'], sep=' ')\n",
    "    target_texts = df['object']\n",
    "\n",
    "    # Create input and target character index mappings\n",
    "    input_characters = sorted(set(' '.join(input_texts)))\n",
    "    target_characters = sorted(set(' '.join(target_texts)))\n",
    "    num_encoder_tokens = len(input_characters)\n",
    "    num_decoder_tokens = len(target_characters)\n",
    "\n",
    "    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "    # Encode input and target sequences as one-hot vectors\n",
    "    max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        for t, char in enumerate(target_text):\n",
    "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(encoder_input_data, decoder_input_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define and compile the NMT model\n",
    "    latent_dim = 256\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the NMT model\n",
    "    batch_size = 64\n",
    "    epochs = 50\n",
    "    history = model.fit([X_train, y_train], y_train, batch_size=batch_size, epochs=epochs, validation_data=([X_val, y_val], y_val))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, GRU, Bidirectional, RepeatVector, TimeDistributed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_dataframe_translation_model_GRU(df):\n",
    "    # Create input and target text sequences\n",
    "    input_texts = df.apply(lambda row: row['subject'] + ' ' + row['predicate'], axis=1)\n",
    "    target_texts = df['object']\n",
    "\n",
    "    # Create input and target character index mappings\n",
    "    input_characters = sorted(set(' '.join(input_texts)))\n",
    "    target_characters = sorted(set(' '.join(target_texts)))\n",
    "    num_encoder_tokens = len(input_characters)\n",
    "    num_decoder_tokens = len(target_characters)\n",
    "\n",
    "    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "    # Encode input and target sequences as one-hot vectors\n",
    "    max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        for t, char in enumerate(target_text):\n",
    "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(encoder_input_data, decoder_input_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define and compile the NMT model with GRU layers\n",
    "    latent_dim = 256\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = Bidirectional(GRU(latent_dim, name=\"gru_sequence_encoder\"), name='bidirectional')\n",
    "    encoder_outputs = encoder(encoder_inputs)\n",
    "\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "    decoder = GRU(latent_dim * 2, return_sequences=True, name='sequence_decoder')\n",
    "    decoder_outputs = decoder(decoder_inputs, initial_state=encoder_outputs)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the NMT model\n",
    "    batch_size = 128\n",
    "    epochs = 1\n",
    "    history = model.fit([X_train, y_train[:, :-1, :]], y_train[:, 1:, :], batch_size=batch_size, epochs=epochs, validation_data=([X_val, y_val[:, :-1, :]], y_val[:, 1:, :]))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80458 samples, validate on 20115 samples\n",
      "Epoch 1/1\n",
      "80458/80458 [==============================] - 230s 3ms/step - loss: 0.3124 - acc: 0.5452 - val_loss: 0.0923 - val_acc: 0.5939\n"
     ]
    }
   ],
   "source": [
    "model = create_dataframe_translation_model_GRU(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Define the input and output dimensions of the model\n",
    "input_dim = 100\n",
    "output_dim = 50\n",
    "\n",
    "latent_dim=256\n",
    "batch_size=64\n",
    "epochs=1\n",
    "\n",
    "# Define the number of hidden units in the model\n",
    "hidden_units = 256"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensors in list passed to 'values' of 'Pack' Op have types [int32, <NOT CONVERTIBLE TO TENSOR>, int32] that don't all match.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001B[0m in \u001B[0;36m_apply_op_helper\u001B[1;34m(self, op_type_name, name, **keywords)\u001B[0m\n\u001B[0;32m    470\u001B[0m                 \u001B[0mpreferred_dtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdefault_dtype\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 471\u001B[1;33m                 as_ref=input_arg.is_ref)\n\u001B[0m\u001B[0;32m    472\u001B[0m             if input_arg.number_attr and len(\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36minternal_convert_n_to_tensor\u001B[1;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001B[0m\n\u001B[0;32m   1292\u001B[0m             \u001B[0mpreferred_dtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpreferred_dtype\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1293\u001B[1;33m             ctx=ctx))\n\u001B[0m\u001B[0;32m   1294\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mret\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36minternal_convert_to_tensor\u001B[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001B[0m\n\u001B[0;32m   1223\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1224\u001B[1;33m       \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1225\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001B[0m in \u001B[0;36m_dimension_tensor_conversion_function\u001B[1;34m(d, dtype, name, as_ref)\u001B[0m\n\u001B[0;32m    357\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 358\u001B[1;33m     \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Cannot convert an unknown Dimension to a Tensor: %s\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    359\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot convert an unknown Dimension to a Tensor: ?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10932\\11215602.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Initialize the GraphTranslationModel object\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGraphTranslationModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlatent_dim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlatent_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10932\\3111469232.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, df, latent_dim, batch_size, epochs)\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecoder_input_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecoder_target_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprepare_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlatent_dim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput_dim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput_dim\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10932\\3111469232.py\u001B[0m in \u001B[0;36mbuild_model\u001B[1;34m(self, input_dim, output_dim, hidden_units)\u001B[0m\n\u001B[0;32m     61\u001B[0m         \u001B[0mdecoder_outputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdecoder_lstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdecoder_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoder_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m         \u001B[0mrepeat_d_layer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRepeatVector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdecoder_outputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m         \u001B[0mrepeat_d\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrepeat_d_layer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mencoder_outputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m         \u001B[0mdecoder_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdecoder_lstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrepeat_d\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoder_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m         \u001B[0mdecoder_dense\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'softmax'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[0;32m    455\u001B[0m             \u001B[1;31m# Actually call the layer,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m             \u001B[1;31m# collecting output(s), mask(s), and shape(s).\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 457\u001B[1;33m             \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    458\u001B[0m             \u001B[0moutput_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_mask\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprevious_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    459\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\keras\\layers\\core.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    555\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    556\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 557\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    558\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001B[0m in \u001B[0;36mrepeat\u001B[1;34m(x, n)\u001B[0m\n\u001B[0;32m   2135\u001B[0m     \u001B[1;32massert\u001B[0m \u001B[0mndim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2136\u001B[0m     \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexpand_dims\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2137\u001B[1;33m     \u001B[0mpattern\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2138\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpattern\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2139\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    179\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 180\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    181\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    182\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mstack\u001B[1;34m(values, axis, name)\u001B[0m\n\u001B[0;32m   1044\u001B[0m                        (axis, -expanded_num_dims, expanded_num_dims))\n\u001B[0;32m   1045\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1046\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mgen_array_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1047\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1048\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001B[0m in \u001B[0;36mpack\u001B[1;34m(values, axis, name)\u001B[0m\n\u001B[0;32m   5895\u001B[0m   \u001B[0maxis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_execute\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_int\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"axis\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5896\u001B[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001B[1;32m-> 5897\u001B[1;33m         \"Pack\", values=values, axis=axis, name=name)\n\u001B[0m\u001B[0;32m   5898\u001B[0m   \u001B[0m_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_op\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5899\u001B[0m   \u001B[0m_inputs_flat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_op\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NMT4RDFS\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001B[0m in \u001B[0;36m_apply_op_helper\u001B[1;34m(self, op_type_name, name, **keywords)\u001B[0m\n\u001B[0;32m    497\u001B[0m                                 (prefix, dtype.name))\n\u001B[0;32m    498\u001B[0m               \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"%s that don't all match.\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mprefix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    500\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               raise TypeError(\n",
      "\u001B[1;31mTypeError\u001B[0m: Tensors in list passed to 'values' of 'Pack' Op have types [int32, <NOT CONVERTIBLE TO TENSOR>, int32] that don't all match."
     ]
    }
   ],
   "source": [
    "# Initialize the GraphTranslationModel object\n",
    "# model = GraphTranslationModel(df_train, latent_dim=latent_dim, batch_size=batch_size, epochs=epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "translations = model.translate(df_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
